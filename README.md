# MBSE Benchmark

A benchmarking framework for evaluating AI models on Model-Based Systems Engineering tasks, with a focus on SysML v2.

## Overview

This tool provides a standardized way to benchmark AI models against a curated set of MBSE tasks, with caching, versioning, and beautiful CLI output.

## Features

- ðŸš€ **Bun-powered** - Fast execution with Bun runtime
- ðŸ¤– **Multi-model support** - Test any AI model via AI SDK (Azure, OpenAI, local models)
- ðŸ“Š **Versioned benchmarks** - Track changes to tasks, tools, and datasets
- ðŸ’¾ **Result caching** - Skip already-run benchmarks unless forced
- ðŸŽ¨ **Beautiful CLI** - Ink-powered terminal interface
- ðŸ“ˆ **GitHub Actions** - Automated benchmark runs with published rankings
- ðŸ”§ **SysML v2 Validators** - Built-in syntax validation and component extraction

## SysML v2 Tasks

The benchmark currently includes SysML v2 tasks for:

- **Validation** (e.g., `sysml-valid-detection-001`): Syntax validation, error detection
- **Extraction** (e.g., `sysml-extract-parts-001`): Part, port, requirement, connection extraction

Additional categories such as analysis, generation, and transformation are planned for future releases.

### Source Models

The SysML v2 models in `data/tasks/models/source/` are from the
[GfSE SysML-v2-Models](https://github.com/GfSE/SysML-v2-Models) repository
(BSD-3-Clause license).

## Installation

### From Release (Recommended)

Download the pre-built binary for your platform from the [Releases](https://github.com/Nepomuceno/mbse_benchmark/releases) page:

- `mbse-bench-linux-x64` - Linux (x64)
- `mbse-bench-linux-arm64` - Linux (ARM64)
- `mbse-bench-darwin-x64` - macOS (Intel)
- `mbse-bench-darwin-arm64` - macOS (Apple Silicon)
- `mbse-bench-windows-x64.exe` - Windows (x64)

### From Source

```bash
bun install
```

### Build Standalone Binary

```bash
bun run build
./dist/mbse-bench --help
```

## Usage

```bash
# Run benchmark for a specific model
bun run bench --model gpt-4

# Run all configured models
bun run bench --all

# Force re-run (ignore cache)
bun run bench --model gpt-4 --force

# List available models
bun run bench --list
```

## Configuration

### Models (`config/models.json`)

Define your AI models with their specifications and credentials:

```json
{
  "models": [
    {
      "id": "gpt-4",
      "name": "GPT-4",
      "provider": "azure",
      "envKey": "AZURE_OPENAI_API_KEY"
    }
  ]
}
```

### Environment Variables

Set credentials for your AI providers:

```bash
# Azure AI Foundry
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com

# OpenAI
OPENAI_API_KEY=your-key

# Local models (Ollama, etc.)
LOCAL_MODEL_URL=http://localhost:11434
```

## Project Structure

```text
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/              # Ink CLI components
â”‚   â”œâ”€â”€ benchmark/        # Benchmark runner logic
â”‚   â”œâ”€â”€ evaluation/       # Evaluation strategies
â”‚   â”‚   â”œâ”€â”€ validators/   # SysML v2 validators
â”‚   â”‚   â””â”€â”€ strategies/   # Scoring strategies
â”‚   â”œâ”€â”€ models/           # AI model adapters
â”‚   â”œâ”€â”€ cache/            # Result caching
â”‚   â””â”€â”€ utils/            # Shared utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tasks/            # Benchmark tasks
â”‚   â”‚   â”œâ”€â”€ models/       # Source SysML models (from GfSE)
â”‚   â”‚   â”‚   â”œâ”€â”€ source/   # Valid models
â”‚   â”‚   â”‚   â””â”€â”€ invalid/  # Intentionally invalid models
â”‚   â”‚   â””â”€â”€ sysml-*/      # Individual task definitions
â”‚   â””â”€â”€ results/          # Cached results
â”œâ”€â”€ config/
â”‚   â””â”€â”€ models.json       # Model configurations
â””â”€â”€ .plan/                # Implementation plans and progress
```

## Benchmark Versioning

The benchmark version is computed from:

- Task definitions
- Available tools
- Evaluation criteria
- Base dataset

Any change to these creates a new version, ensuring result comparability.

## Results

Results are stored in `data/results/` with the structure:

```text
data/results/
â”œâ”€â”€ v1.0.0/
â”‚   â”œâ”€â”€ gpt-4.json
â”‚   â””â”€â”€ claude-3.json
â””â”€â”€ v1.1.0/
    â””â”€â”€ gpt-4.json
```

## License

MIT License - Gabriel Nepomuceno

## Contributing

See [AGENTS.md](./AGENTS.md) for AI agent contribution guidelines.
